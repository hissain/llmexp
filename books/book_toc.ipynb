{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a0d6d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse JSON response: {\n",
      "  \"Table_of_Contents\": [\n",
      "    {\n",
      "      \"Chapter_1\": {\n",
      "        \"Title\": \"Introduction to Prompt Engineering\",\n",
      "        \"Subsections\": [\"What is prompt engineering?\", \"Importance of Effective Communication\"]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"Chapter_2\": {\n",
      "        \"Title\": \"Principles and Best Practices in Prompt Design\",\n",
      "        \"Subsections\": [\n",
      "          \"Understanding the target AI model's limitations\", \n",
      "          \"Using clear, concise language\"\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"Chapter_3\": {\n",
      "        \"Title\": \"Prompt Structuring Techniques for Effective Communication\",\n",
      "        \"Subsections\": [\n",
      "          \"How to structure a prompt effectively?\", \n",
      "          \"Using examples and providing context\"\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"Chapter_4\": {\n",
      "        \"Title\": \"Techniques for Dynamic Prompt Adjustment during Interaction\",\n",
      "        \"Subsections\": [\n",
      "          \"Adapting prompts based on AI response patterns\", \n",
      "          \"Identifying the need to modify a prompt mid-interaction\"\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"Chapter_5\": {\n",
      "        \"Title\": \"Common Pitfalls in Prompt Engineering and How to Avoid Them\",\n",
      "        \"Subsections\": [\n",
      "          \"Avoiding ambiguous language when crafting prompts\", \n",
      "          \"Recognizing the potential for bias or misinterpretation\"\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"Chapter_6\": {\n",
      "        \"Title\": \"Ethical Considerations in Prompt Engineering\",\n",
      "        \"Subsections\": [\n",
      "          \"The responsibility of providing accurate and unbiased information through prompts\", \n",
      "          \"Considering the impact on user experience\"\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"Chapter_7\": {\n",
      "        \"Title\": \"Future Trends in Prompt Engineering and Best Practices for Keeping Up-to-Date\",\n",
      "        \"Subsections\": [\n",
      "          \"Emerging technologies influencing prompt engineering techniques\", \n",
      "          \"Keeping abreast of changes through continuous learning\"\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"Chapter_8\": {\n",
      "        \"Title\": \"Summary and Recommendations for Effective Prompt Engineering\",\n",
      "        \"Subsections\": [\"Wrap-up thoughts on effective prompt engineering practices\"] \n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"Glossary\": {\n",
      "        \"Terms\": [\n",
      "          {\"Prompt_Engineering\": \"The art and science of crafting instructions for AI models to ensure accurate, efficient communication\"},\n",
      "          ... (Other terms related to prompt engineering)\n",
      "        ] \n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "ollama_url_gen = \"http://localhost:11434/api/generate\"\n",
    "ollama_model_name = \"phi3\"\n",
    "\n",
    "def generate_toc_prompt(subject):\n",
    "    return f\"\"\"\n",
    "You are an expert assistant specializing in creating structured and logical book outlines.\n",
    "Your task is to generate a detailed Table of Contents for a book on the given subject.\n",
    "Each chapter must have a title, and chapters can include subsections and examples where applicable.\n",
    "The Table of Contents should be well-structured, logically ordered, and strictly formatted as a valid JSON object without any extra text.\n",
    "Be extra cautious to place comma between items. Multiple items within one key should be like array element in valid json format.\n",
    "\n",
    "Format:\n",
    "{{\n",
    "    \"Table_of_Contents\": [\n",
    "        {{\n",
    "            \"Chapter 1\": \"Title of Chapter\",\n",
    "            \"Sections\": [\n",
    "                \"Section 1.1: Title of Section\",\n",
    "                \"Section 1.2: Title of Section\"\n",
    "            ]\n",
    "        }},\n",
    "        {{\n",
    "            \"Chapter 2\": \"Title of Chapter\",\n",
    "            \"Sections\": [\n",
    "                \"Section 2.1: Title of Section\",\n",
    "                \"Section 2.2: Title of Section\"\n",
    "            ]\n",
    "        }}\n",
    "    ]\n",
    "}}\n",
    "\n",
    "Subject: {subject}\n",
    "\"\"\"\n",
    "    payload = {\"model\": model, \"prompt\": prompt, \"stream\": False}\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    response = requests.post(ollama_url_gen, headers=headers, data=json.dumps(payload))\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Error from Ollama: {response.text}\")\n",
    "    \n",
    "    content = response.json().get(\"response\", \"\")\n",
    "    try:\n",
    "        # Extract potential JSON array or object\n",
    "        json_match = re.search(r\"\\{.*\\}|\\[.*\\]\", content, re.DOTALL)\n",
    "        if json_match:\n",
    "            raw_json = json_match.group()\n",
    "            \n",
    "            # Attempt to fix common issues, such as missing commas between JSON objects\n",
    "            sanitized_json = re.sub(r'(\\}|\"[^\"]*\")\\s*(\"[^\"]*\":)', r'\\1,\\2', raw_json)\n",
    "            return json.loads(sanitized_json)\n",
    "        else:\n",
    "            raise Exception(f\"Valid JSON not found in response: {content}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise Exception(f\"Failed to parse JSON response after sanitization: {sanitized_json}\") from e\n",
    "\n",
    "try:\n",
    "    toc = generate_toc(\"Prompt Engineering\")\n",
    "    print(json.dumps(toc, indent=4))\n",
    "except Exception as e:\n",
    "    print(str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afe2b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_toc(\"Prompt Engineering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e66722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "ollama_url_gen = \"http://localhost:11434/api/generate\"\n",
    "ollama_model_name = \"phi3\"\n",
    "\n",
    "def generate_section(chapter_title, model=ollama_model_name):\n",
    "    prompt = f\"\"\"\n",
    "You are a knowledgeable assistant tasked with writing detailed content for a book.\n",
    "Please write content for the following chapter or section title:\n",
    "Title: {chapter_title}\n",
    "\n",
    "The content should be comprehensive, logically structured, and suitable for a technical book. Ensure it includes examples where relevant.\n",
    "\"\"\"\n",
    "    payload = {\"model\": model, \"prompt\": prompt, \"stream\": False}\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    response = requests.post(ollama_url_gen, headers=headers, data=json.dumps(payload))\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Error from Ollama: {response.text}\")\n",
    "    \n",
    "    return response.json().get(\"response\", \"\")\n",
    "\n",
    "# Example usage\n",
    "for item in toc[\"Table_of_Contents\"]:\n",
    "    for chapter, title in item.items():\n",
    "        print(f\"Generating content for {chapter}: {title}\")\n",
    "        content = generate_section(title)\n",
    "        with open(f\"{chapter}.txt\", \"w\") as file:\n",
    "            file.write(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b526d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from fpdf import FPDF\n",
    "\n",
    "# Ollama API configuration\n",
    "OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
    "MODEL_NAME = \"phi3\"\n",
    "\n",
    "# Directory to save generated content\n",
    "OUTPUT_DIR = \"book_content\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def generate_toc(subject):\n",
    "    \"\"\"Generate a Table of Contents for the given subject.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert assistant skilled at creating book outlines.\n",
    "    Create a detailed Table of Contents for a book on the following subject:\n",
    "    Subject: {subject}\n",
    "    \n",
    "    Structure the response as a valid JSON object with chapters and sections:\n",
    "    {{\n",
    "        \"Table_of_Contents\": [\n",
    "            {{\n",
    "                \"Chapter 1\": \"Title of Chapter\",\n",
    "                \"Sections\": [\n",
    "                    \"Section 1.1: Title of Section\",\n",
    "                    \"Section 1.2: Title of Section\"\n",
    "                ]\n",
    "            }},\n",
    "            {{\n",
    "                \"Chapter 2\": \"Title of Chapter\",\n",
    "                \"Sections\": [\n",
    "                    \"Section 2.1: Title of Section\",\n",
    "                    \"Section 2.2: Title of Section\"\n",
    "                ]\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    payload = {\"model\": MODEL_NAME, \"prompt\": prompt, \"stream\": False}\n",
    "    response = requests.post(OLLAMA_URL, json=payload)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Error from Ollama: {response.text}\")\n",
    "    \n",
    "    content = response.json().get(\"response\", \"\")\n",
    "    try:\n",
    "        toc = json.loads(content)\n",
    "        return toc\n",
    "    except json.JSONDecodeError:\n",
    "        raise Exception(f\"Failed to parse ToC JSON: {content}\")\n",
    "\n",
    "def generate_section(title):\n",
    "    \"\"\"Generate content for a given chapter or section title.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are a knowledgeable assistant tasked with writing detailed content for a book.\n",
    "    Please write content for the following chapter or section:\n",
    "    Title: {title}\n",
    "    \n",
    "    The content should be comprehensive, well-structured, and professional.\n",
    "    Include examples, subtopics, and technical insights where applicable.\n",
    "    \"\"\"\n",
    "    payload = {\"model\": MODEL_NAME, \"prompt\": prompt, \"stream\": False}\n",
    "    response = requests.post(OLLAMA_URL, json=payload)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Error from Ollama: {response.text}\")\n",
    "    \n",
    "    return response.json().get(\"response\", \"\")\n",
    "\n",
    "def save_content_to_file(filename, content):\n",
    "    \"\"\"Save generated content to a file.\"\"\"\n",
    "    with open(os.path.join(OUTPUT_DIR, filename), \"w\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "def create_pdf_from_content(toc, output_file=\"Generated_Book.pdf\"):\n",
    "    \"\"\"Generate a PDF book from the content.\"\"\"\n",
    "    pdf = FPDF()\n",
    "    pdf.set_auto_page_break(auto=True, margin=15)\n",
    "    pdf.set_left_margin(15)\n",
    "    pdf.set_right_margin(15)\n",
    "    \n",
    "    # Title Page\n",
    "    pdf.add_page()\n",
    "    pdf.set_font(\"Arial\", size=24, style=\"B\")\n",
    "    pdf.cell(0, 10, \"Generated Book\", ln=True, align=\"C\")\n",
    "    pdf.ln(20)\n",
    "    \n",
    "    # Table of Contents\n",
    "    pdf.set_font(\"Arial\", size=16, style=\"B\")\n",
    "    pdf.cell(0, 10, \"Table of Contents\", ln=True)\n",
    "    pdf.ln(10)\n",
    "    pdf.set_font(\"Arial\", size=12)\n",
    "    for chapter in toc[\"Table_of_Contents\"]:\n",
    "        for chapter_title, sections in chapter.items():\n",
    "            pdf.cell(0, 10, chapter_title, ln=True)\n",
    "            if isinstance(sections, dict):\n",
    "                for section_title in sections.get(\"Sections\", []):\n",
    "                    pdf.cell(10, 10, f\"  {section_title}\", ln=True)\n",
    "            pdf.ln(5)\n",
    "    \n",
    "    # Chapters\n",
    "    for chapter in toc[\"Table_of_Contents\"]:\n",
    "        for chapter_title, sections in chapter.items():\n",
    "            pdf.add_page()\n",
    "            pdf.set_font(\"Arial\", size=18, style=\"B\")\n",
    "            pdf.cell(0, 10, chapter_title, ln=True)\n",
    "            pdf.ln(10)\n",
    "            \n",
    "            filename = f\"{chapter_title.replace(' ', '_')}.txt\"\n",
    "            file_path = os.path.join(OUTPUT_DIR, filename)\n",
    "            if os.path.exists(file_path):\n",
    "                with open(file_path, \"r\") as f:\n",
    "                    content = f.read()\n",
    "                pdf.set_font(\"Arial\", size=12)\n",
    "                pdf.multi_cell(0, 10, content)\n",
    "    \n",
    "    pdf.output(output_file)\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    subject = \"Prompt Engineering\"\n",
    "    print(f\"Generating Table of Contents for subject: {subject}\")\n",
    "    \n",
    "    # Step 1: Generate ToC\n",
    "    toc = generate_toc(subject)\n",
    "    print(\"Table of Contents generated successfully.\")\n",
    "    \n",
    "    # Step 2: Generate content for each chapter/section\n",
    "    for chapter in toc[\"Table_of_Contents\"]:\n",
    "        for chapter_title, sections in chapter.items():\n",
    "            print(f\"Generating content for {chapter_title}...\")\n",
    "            chapter_content = generate_section(chapter_title)\n",
    "            save_content_to_file(f\"{chapter_title.replace(' ', '_')}.txt\", chapter_content)\n",
    "            \n",
    "            if \"Sections\" in sections:\n",
    "                for section_title in sections[\"Sections\"]:\n",
    "                    print(f\"Generating content for {section_title}...\")\n",
    "                    section_content = generate_section(section_title)\n",
    "                    save_content_to_file(f\"{section_title.replace(' ', '_')}.txt\", section_content)\n",
    "    \n",
    "    # Step 3: Create PDF\n",
    "    print(\"Merging content into a PDF book...\")\n",
    "    create_pdf_from_content(toc)\n",
    "    print(\"PDF book generated successfully: Generated_Book.pdf\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
