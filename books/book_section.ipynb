{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "488f99a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install fpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fe57a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from fpdf import FPDF\n",
    "\n",
    "# Ollama API configuration for chat\n",
    "OLLAMA_URL = \"http://localhost:11434/api/chat\"\n",
    "MODEL_NAME = \"phi3\"\n",
    "\n",
    "# Directory to save generated content\n",
    "OUTPUT_DIR = \"book_content\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def generate_toc(subject):\n",
    "    \"\"\"Generate a Table of Contents for the given subject using chat API.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert assistant skilled at creating book outlines.\n",
    "    Create a detailed Table of Contents for a book on the following subject:\n",
    "    Subject: {subject}\n",
    "    \n",
    "    Structure the response as a valid JSON object with chapters and sections:\n",
    "    {{\n",
    "        \"Table_of_Contents\": [\n",
    "            {{\n",
    "                \"Chapter 1\": \"Title of Chapter\",\n",
    "                \"Sections\": [\n",
    "                    \"Section 1.1: Title of Section\",\n",
    "                    \"Section 1.2: Title of Section\"\n",
    "                ]\n",
    "            }},\n",
    "            {{\n",
    "                \"Chapter 2\": \"Title of Chapter\",\n",
    "                \"Sections\": [\n",
    "                    \"Section 2.1: Title of Section\",\n",
    "                    \"Section 2.2: Title of Section\"\n",
    "                ]\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Chat API expects a list of messages with roles like \"system\", \"user\", and \"assistant\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert book creator.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    \n",
    "    # Sending the request with a high timeout (e.g., 120 seconds)\n",
    "    payload = {\"model\": MODEL_NAME, \"messages\": messages}\n",
    "    try:\n",
    "        response = requests.post(OLLAMA_URL, json=payload, timeout=120)\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"Error from Ollama: {response.text}\")\n",
    "\n",
    "        content = response.json().get(\"response\", \"\")\n",
    "        try:\n",
    "            toc = json.loads(content)\n",
    "            return toc\n",
    "        except json.JSONDecodeError:\n",
    "            raise Exception(f\"Failed to parse ToC JSON: {content}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise Exception(f\"Request failed: {str(e)}\")\n",
    "\n",
    "# Example usage\n",
    "subject = \"Prompt Engineering\"\n",
    "toc = generate_toc(subject)\n",
    "print(\"Table of Contents generated:\", toc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
